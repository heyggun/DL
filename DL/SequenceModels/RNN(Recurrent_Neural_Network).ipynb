{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3036f474",
   "metadata": {},
   "source": [
    "# RNN(Recurrent Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40972931",
   "metadata": {},
   "source": [
    "## `keras로 RNN 구현`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf40bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d074b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (None, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# hidden_units = 3 (메모리 셀이 다음 시점의 메모리 셀과 출력층으로 보내는 값의 크기)\n",
    "# input_shape = (timesteps, input_dim)  timesteps : 입력 시퀀스의 길이, 시점의 수 / input_dim : 입력의 크기\n",
    "model.add(SimpleRNN(3, input_shape=(2,10)))  \n",
    "#model.add(SimpleRNN(3, input_length=2, input_dim=10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929e3e6b",
   "metadata": {},
   "source": [
    "    -> 출력값(batch_size, output_dim) 크기의 2D tensor 일때, output_dim은 hidden_units의 값 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11389255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (8, 3)                    42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8,2,10)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04686615",
   "metadata": {},
   "source": [
    "    -> batch_size 8로 기재, 출력의 크기 (8,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cad1e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_3 (SimpleRNN)    (8, 2, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8,2,10), return_sequences=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ef755",
   "metadata": {},
   "source": [
    "    -> batch_size, timesteps, output_dim 크기의 3D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26834669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b708f204",
   "metadata": {},
   "source": [
    "## `Python의 Numpy로 RNN 구현`"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "728960ca",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2364ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e75d71df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 은닉 상태 -> [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " 가중치 Wx -> (8, 4)\n",
      " 가중치 Wh -> (8, 8)\n",
      " 편향 b -> (8,)\n",
      " 모든 시점의 hidden states = \n",
      " [[0.72142611 0.89115199 0.68385193 0.84210824 0.93933851 0.85704589\n",
      "  0.90456349 0.78545465]\n",
      " [0.99997748 0.99998437 0.99956839 0.9997046  0.99991349 0.99994163\n",
      "  0.99991812 0.99998583]\n",
      " [0.99999249 0.99999042 0.99989187 0.99994518 0.99990426 0.99998244\n",
      "  0.99990207 0.99998696]\n",
      " [0.99999889 0.99999859 0.99997727 0.99997844 0.99999251 0.99999718\n",
      "  0.9999895  0.99999836]\n",
      " [0.99999763 0.9999957  0.9999407  0.99994209 0.99997428 0.99999399\n",
      "  0.99997107 0.99999671]\n",
      " [0.99999375 0.99999067 0.99982084 0.99982916 0.99993968 0.99998611\n",
      "  0.99995133 0.99999554]\n",
      " [0.99999835 0.99999496 0.99995066 0.99993855 0.99997083 0.99999505\n",
      "  0.99996443 0.99999665]\n",
      " [0.99999378 0.99999411 0.99989996 0.99990501 0.99993317 0.99997949\n",
      "  0.99994141 0.99999461]\n",
      " [0.99999759 0.99999434 0.99993618 0.99987291 0.99994622 0.99998843\n",
      "  0.99994714 0.9999969 ]\n",
      " [0.99999869 0.99999805 0.99997408 0.99995694 0.99998308 0.99999413\n",
      "  0.99997929 0.99999817]]\n"
     ]
    }
   ],
   "source": [
    "timesteps, input_dim, hidden_units= 10, 4,8\n",
    "\n",
    "# input 2d tensor\n",
    "inputs = np.random.random((timesteps, input_dim))\n",
    "\n",
    "# 초기 은닉상태 0 vector\n",
    "\n",
    "hidden_state_t = np.zeros((hidden_units))\n",
    "\n",
    "print(f\"초기 은닉 상태 -> {hidden_state_t}\")\n",
    "\n",
    "Wx = np.random.random((hidden_units, input_dim))   # (8,4) 크기의 2d tensor, input에 대한 weight\n",
    "Wh = np.random.random((hidden_units, hidden_units)) # (8,8) 크기의 2d tensor, hidden state에 대한 weight\n",
    "b = np.random.random((hidden_units, )) #(8,) 크기의 1d tensor, bias\n",
    "\n",
    "print(f\" 가중치 Wx -> {np.shape(Wx)}\")\n",
    "print(f\" 가중치 Wh -> {np.shape(Wh)}\")\n",
    "print(f\" 편향 b -> {np.shape(b)}\")\n",
    "\n",
    "\n",
    "total_hidden_states = []\n",
    "\n",
    "# 각 timesteps 간 input\n",
    "\n",
    "for input_t in inputs:\n",
    "    \n",
    "    # Wx * Xt + Wh * Ht-1 + b\n",
    "    output_t = np.tanh(np.dot(Wx, input_t) + np.dot(Wh, hidden_state_t)+b)\n",
    "    \n",
    "    # 각 시점 t별 메모리 셀의 출력의 크기 (timestep t, ouput_dim)\n",
    "    # 각 시점의 은닉 상태를 계속해서 누적\n",
    "    total_hidden_states.append(list(output_t))\n",
    "    hidden_state_t = output_t\n",
    "    \n",
    "# 출력 시 값을 깔끔하게 함\n",
    "total_hidden_states= np.stack(total_hidden_states, axis=0)\n",
    "\n",
    "\n",
    "#모든 시점의 은닉상태\n",
    "print(f\" 모든 시점의 hidden states = \\n {total_hidden_states}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907bffdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d8214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e5db356",
   "metadata": {},
   "source": [
    "# Q.\n",
    "\n",
    "    단어 집합(Vocabulary)의 크기가 5,000이고 임베딩 벡터의 차원은 100이다.\n",
    "    은닉층에서는 Simple RNN으로 은닉 상태의 크기는 128이고, 은닉층은 1개이다.\n",
    "    훈련에 사용하는 모든 샘플의 길이는 30으로 가정할 때, \n",
    "    이진 분류를 수행하는 모델로, 출력층의 뉴런은 1개로 시그모이드 함수를 사용할때의 RNN 모델 구현 및 parameter 개수?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bba3e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1abbb7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         500000    \n",
      "                                                                 \n",
      " simple_rnn_4 (SimpleRNN)    (None, 128)               29312     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 529,441\n",
      "Trainable params: 529,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "embedding_dim = 100\n",
    "hidden_size =128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(SimpleRNN(hidden_size))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587e4b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
